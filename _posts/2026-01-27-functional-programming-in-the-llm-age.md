---
author: Abiola Lapite
mathjax: true
tags:
  - Large Language Models
  - Machine Learning
  - Functional Programming
  - Programming
  - Scala
categories: programming
---

It seems clear to me that over the last 10 years, there's been a dramatic decline in interest in functional-programming languages like Haskell and (in particular) Scala. I wish I could say this development has come as a surprise to me, but it hasn't in the least. What appealed to me about languages like Haskell and Scala was precisely what I thought would end up working to the detriment of the languages, namely, the opportunity to take seriously the [Curry-Howard correspondence](https://en.wikipedia.org/wiki/Curry%E2%80%93Howard_correspondence) between computer programs and mathematical proofs. 

A strictly functional approach would have opened the door to applying insights from [category theory](https://en.wikipedia.org/wiki/Category_theory) to real-world programming. This in turn would have made it possible to leave behind the world of stateful objects and pre-baked design patterns, and replacing these old notions with clearer concepts which could be rigorously reasoned about. In this brave new world, programs could essentially be delegated to the type-system, so that one could be absolutely certain that any passing code would do the right thing under all circumstances (assuming its initial premises correctly captured whatever goal the program was written for). While problem-free concurrency was usually pushed as the main selling-point for a purely functional approach, the elimination of most of the concurrency issues which plagued (and still plagues) traditional software would have been just one concrete manifestation of all the benefits that would have accrued. 

On paper, the argument for pure FP was compelling, but once efforts began to translate it into the real world of commercial programming, difficulties quickly become apparent. Not least of these difficulties was that most programmers (and most STEM people who aren't mathemticians) get no exposure to category theory in the course of their educations, and aren't used to the careful step-by-step reasoning from axioms that is the bread and butter of the world of pure mathematics. When faced with calls to quickly adopt reams of utterly unfamilar ideas about ["morphisms"](https://en.wikipedia.org/wiki/Morphism), ["functors"](https://en.wikipedia.org/wiki/Functor), ["monads"](https://en.wikipedia.org/wiki/Monad_(category_theory)), ["natural transformations"](https://en.wikipedia.org/wiki/Natural_transformation) and the like, they understandably struggle, especially when faced with ["diagram chasing"](https://en.wikipedia.org/wiki/Commutative_diagram#Diagram_chasing) commutative diagrams. As a particularly [notorious joke](https://stackoverflow.com/questions/3870088/a-monad-is-just-a-monoid-in-the-category-of-endofunctors-whats-the-problem) on the whole business goes, _"A monad is just a monoid in the category of endofunctors, what's the problem?"_

With all of the above in mind, it's not surprising that an entire industry sprang up around writing [monad tutorials](https://wiki.haskell.org/Monad_tutorials_timeline), most of which had the perverse effect of worsening understanding of the concept, due to their inprecision. One person says _"a monad is just like a burrito"_, then another says _"no, it's actually like a spaceship"_, and now a third pops up to insist _"actually, a monad is like a railway"_, and on and on the sloppy metaphors go, leaving trails of confusion in their wake. The funny thing is that, setting aside all the fancy LaTeX typesetting and the preparatory definitional jargon, the actual mathematical ideas are themselves quite simple, and once one grasps them, the likely reaction will be _"So that's all there is to it?"_ Unfortunately most programmers trying to get into the topic won't manage to stumble upon a [decent tutorial](https://github.com/hmemcpy/milewski-ctfp-pdf) before deciding it's all too much, and retreating to the world of OOP and [Gang of Four design patterns](https://en.wikipedia.org/wiki/Design_Patterns). For all their flaws, these old ideas are much easier to grasp, and numerous implementations of them are available in any reasonably popular language. 

The way I see it, the difference between the GoF OOP world and the shiny new world of pure FP is analogous to the difference between how Roman engineers built their public works, and how modern civil engineers approach the same task. The builder of the Roman temples, bridges, roads and viaducts didn't have the well-worked out theories of physics and scientific understanding of materials modern engineers do, so they worked from formulae derived over centuries of painful trial and error. As long as the Roman engineers stuck to these tried and tested methods, they could be sure that what they built would last, and there is [no shortage](https://en.wikipedia.org/wiki/Pantheon,_Rome) of [surviving evidence](https://en.wikipedia.org/wiki/Aqueduct_of_Segovia) that the Romans were correct in their assumptions about the durability of their constructions. 

In contrast to the Roman way of doing things, modern engineers know exactly why they make the choices they do, and as such, they are able to precisely meet the demands of clients for structures of a scale and capacity the ancient Romans would have had trouble even imagining. If modern roads, buildings and bridges fail to last even a century, that is **not** because modern engineers are incapable of building for millenia to come. On the contrary, it is precisely **because** modern engineers have a rigorous understanding of what they are doing that they are able to build to match the 50 or 75 year criteria that their clients want, avoiding any waste of effort and material on creating things which weren't meant to last long anyway. That this time-horizon is often at variance with what the  public expects or demands is a separate matter entirely ...  

Returning to the original theme, the huge hurdles to the adoption of pure FP brought repercussions in how well it could be adopted in the workplace. Many companies soon found that programmers who truly grasped pure FP (rather than merely, say, using Scala as a fancier Java) proved difficult, so they had to offer higher salaries. Making matters worse, the maintainers of the Scala language, which had been enjoying some popular due to its availability on the JVM, then decided to release a new, backwards-incompatible version of the language while deprecating the version actually in mainstream use. While the Scala language maintainers had quite sensible reasons for making breaking changes, they failed to take seriously enough the commercial impact of their approach. Scala 3 was different enough from Scala 2 to make it feel as if one were learning a new language, with the added drawbacks of poor IDE support and incompatibility with important 3rd party libraries. To illustrate, 4 years on from the release of Scala 3, and IntelliJ IDEA support for the language is **still** unsatisfactory.          

## How "Agentic" Programming Changes Things
Over the last year, large-language models become capable enough to be used to drive programming tools in non-trivial scenarios. While most of the recent hype has centred on Anthropic's "Claude Code"/"Opus 4.5" combination, OpenAI's "Codex"/"GPT 5.2" seems broadly comparable in capabilities, while many others besides me have seen success using model-agnostic harnesses like OpenCode with leading "open-weight" Chinese models like MiniMax M2.1 and GLM 4.7. "Agentic" coding seems to be the first meaningful application of LLMs in which the intention is to produce something other than purely derivative "slop" fit mostly for spamming, scamming and running astroturf campaigns. What makes the application of LLMs to programming different from the many other uses to which people have tried to put them?

Perhaps the most important difference between programming and most other intended fields of usage is that in programming, there are (for the most part) clearcut ways of determining correctness, and these means are largely automatable. Programs have to fulfill basic syntactic conditions to even be interpreted or compiled. Beyond that initial bar, programs must also meet the conditions of linters, unit/integration test coverage, automated security scans, etc. In short, the software development process provides plenty of automatic, unambiguous feedback for the purpose of training machine-learning models. Couple this with the copious amount of free training data available on sites like GitHub, and it's easy to see why programming should be proving so much more tractable than, say, offering online support to users who are free to pose any questions they please, and in all the glorious ambiguity of natural language.

As plentiful as the freely available, online training data for programming has been, it isn't infinite in extent, and I suspect that almost every repository worth peeking at has already been scanned many times over by now. Making matters worse going forward, an increasing percentage of the new code being uploaded to the web will almost certainly be of the "vibe coded" variety, meaning model-trainers will have to worry more and more about an [ouroboros](https://en.wikipedia.org/wiki/Ouroboros) like circularity in the training process. 

What makes this development troubling for model-developers is that the with "vibe code" generated for users who either lack programming skills or lack interest in expending effort on code quality, most of the old indicators of quality will lose their predictive power. It used to be possible for scientists to tell the cranks from serious correspondents through "tells" such as idiosyncratic spelling and terrible grammar, but that now chatbots make it possible for crackpots to generate perfectly grammatical screeds with impeccable spelling, telling the kooks apart has become a lot harder. The ability of agentic-coding frameworks to generate syntactically valid code that passes standard linting, code-coverage and security tests presents LLM developers with much the same challenge from here on out. Just because code compiles, passes stylistic checks, and has no glaring security issues, doesn't mean the code actually captures the **intent** behind its creation.  

## Functional Programming to the Rescue?
If model developers can't rely on getting access to vast new amounts of code to train their models, what choice is left to them? The obvious one is to use **synthetic** data, but what would that look like in the realm of programming?  