---
author: Abiola Lapite
mathjax: true
tags: mathematics
categories: mathematics
---
Lately, there's been a lot of online buzz about the capabilities of Anthropic's ["Claude Code"](https://claude.com/product/claude-code) offering, and how it's supposedly making a tremendous difference to how developers are approaching their jobs. Going by what one sees on sites like Reddit and Hacker News, nothing less than a top-tier _Claude Code Max_ account will do to experience this wonderful new world, but we're hardly talking chicken change at £200/month. It may be that many of those raving about Claude Code are having their accounts paid for by their employers, but what if that isn't an option? Is there really no choice but to swallow any reservations and hand over all that money to Anthropic, no matter one's personal circumstances? 

What confuses things further is that there is a distinction to be made between _Claude Code_ as an *interface*, and the "Opus 4.5" model which is currently Anthropic's top tier offering. How much of the rhapsodising over the "Claude Code" experience is due to the model itself, and how much owes to the CLI wrapper which drives it? As Anthropic does not allow usage of the Claude Code CLI without a paid Claude Code subscription, it isn't really possible to investigate this question without spending at least £20/month for a highly restrictive "Pro" plan which is unusable for any truly professional purpose.

Fortunately, it turns out that alternatives to Claude Code do exist, and many of them are open-source. In particular, I've been examining [Zed](https://zed.dev/), [Cline](https://cline.bot/), [Kilo Code](https://kilo.ai/) and [OpenCode](https://opencode.ai/). All four tools offer the ability to integrate with a wide variety of models either directly to the companies offering them, or via third-parties such as [OpenRouter](https://openrouter.ai/). While all of these tools have the same subscription model as Anthropic/Claude and OpenAI/Codex, none of them compel users to subscribe to anything to use them. 

For my purposes, I've stuck mostly to using OpenRouter with a pre-paid balance, which allows me to switch between model providers at will even during a single coding session. To keep costs manageable, I've stayed clear of Anthropic's models, and only occasionally made use of [GPT 5.2](https://openai.com/index/introducing-gpt-5-2/). Most of my initial "vibe coding" was done with [GLM 4.5 Air](https://huggingface.co/zai-org/GLM-4.5-Air), and then later with [GLM 4.7](https://huggingface.co/zai-org/GLM-4.7), but of late, my mainstay has been [Minimax M2.1](https://huggingface.co/MiniMaxAI/MiniMax-M2.1), which I've found to be superior to the GLM models in compliance with instructions, as well as in the quality of the code it generates, at least when the language is one of Swift, Python or Java. 

When it comes to how it feels to use these tools in practice, I can't say there's a great amount of difference, as they all seem to have converged on a workflow which I imagine was pioneered by Claude Code: there's a read-only "Plan" mode in which one can discuss various aspects of the model with the codebase, in the confidence that no changes will result, and then there's a "Build" mode in which one instructs the model to actually make changes, whether these be refactoring, augmenting existing code, creating new classes or something else. An important aspect of this "Plan" vs. "Build" distinction is that the model used in the "Plan" phase need **not** be the same as the one used in the "Build" phase. For example, one might use an expensive model like GPT 5.2 for planning, and then, once the plans are finalised, switch to a much cheaper model like Minimax M2.1 to execute on those plans. 