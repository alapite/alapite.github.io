---
author: Abiola Lapite
mathjax: true
tags: mathematics
categories: mathematics
---
Lately, there's been a lot of online buzz about the capabilities of Anthropic's ["Claude Code"](https://claude.com/product/claude-code) offering, and how it's supposedly making a tremendous difference to how developers are approaching their jobs. Going by what one sees on sites like Reddit and Hacker News, nothing less than a top-tier _Claude Code Max_ account will do to experience this wonderful new world, but we're hardly talking chicken change at £200/month. It may be that many of those raving about Claude Code are having their accounts paid for by their employers, but what if that isn't an option? Is there really no choice but to swallow any reservations and hand over all that money to Anthropic, no matter one's personal circumstances? 

What confuses things further is that there is a distinction to be made between _Claude Code_ as an *interface*, and the "Opus 4.5" model which is currently Anthropic's top tier offering. How much of the rhapsodising over the "Claude Code" experience is due to the model itself, and how much owes to the CLI wrapper which drives it? As Anthropic does not allow usage of the Claude Code CLI without a paid Claude Code subscription, it isn't really possible to investigate this question without spending at least £20/month for a highly restrictive "Pro" plan which is unusable for any truly professional purpose.

Fortunately, it turns out that alternatives to Claude Code do exist, and many of them are open-source. In particular, I've been examining [Zed](https://zed.dev/), [Cline](https://cline.bot/), [Kilo Code](https://kilo.ai/) and [OpenCode](https://opencode.ai/). All four tools offer the ability to integrate with a wide variety of models either directly to the companies offering them, or via third-parties such as [OpenRouter](https://openrouter.ai/). While all of these tools have the same subscription model as Anthropic/Claude and OpenAI/Codex, none of them compel users to subscribe to anything to use them. 

For my purposes, I've stuck mostly to using OpenRouter with a pre-paid balance, which allows me to switch between model providers at will even during a single coding session. To keep costs manageable, I've stayed clear of Anthropic's models, and only occasionally made use of [GPT 5.2](https://openai.com/index/introducing-gpt-5-2/). Most of my initial "vibe coding" was done with [GLM 4.5 Air](https://huggingface.co/zai-org/GLM-4.5-Air), and then later with [GLM 4.7](https://huggingface.co/zai-org/GLM-4.7), but of late, my mainstay has been [Minimax M2.1](https://huggingface.co/MiniMaxAI/MiniMax-M2.1), which I've found to be superior to the GLM models in compliance with instructions, as well as in the quality of the code it generates, at least when the language is one of Swift, Python or Java. 

When it comes to how it feels to use these tools in practice, I can't say there's a great amount of difference, as they all seem to have converged on a workflow which I imagine was pioneered by Claude Code: there's a read-only "Plan" mode in which one can discuss various aspects of the model with the codebase, in the confidence that no changes will result, and then there's a "Build" mode in which one instructs the model to actually make changes, whether these be refactoring, augmenting existing code, creating new classes or something else. An important aspect of this "Plan" vs. "Build" distinction is that the model used in the "Plan" phase need **not** be the same as the one used in the "Build" phase. For example, one might use an expensive model like GPT 5.2 for planning, and then, once the plans are finalised, switch to a much cheaper model like Minimax M2.1 to execute on those plans.

In my initial attempts at using these tools to write code, I tried to play it safe by only making additive changes to codebases I already understood thoroughly (and which were in languages I knew well). None of the tools provide much guidance for how to make best use of large-language models as part of a structured development process, so I began by simply asking for what I wanted in as straightforward terms as possible, e.g. _"Use the Spring AI library to add an MCP server which can execute Google searches"_. 

Starting with the GLM 4.5 Air and 4.7 models, the initial results seemed impressive (especially given the voluminous log output of the "thinking" process), but on closer examination there were always issues, such as Spring annotations being applied at the wrong level (e.g. to a class rather than to a method in it), Lombok annotations being replaced with hardcoded uses of the SLF4J library, or project dependencies being rolled back to outdated versions, many of which had already been flagged as having security issues. 

Switching to Minimax M2.1 lessened the frequency of occurrence of such problems, but it didn't eliminate them completely, and I found myself spending so much time reviewing the code changes for insidious problems that it would have taken less time to have simply written the code by hand in the first place. Switching from Minimax 2.1 to Google's [Gemini 3 Flash](https://blog.google/products-and-platforms/products/gemini/gemini-3-flash/) didn't bring any appreciable benefit despite costing considerably more, and Google's model was being praised to the skies online not so long ago. Was this really what everyone was getting excited about? Was it a model issue, with Anthropic's Opus 4.5 that much better than the competition? Or did the problem lie in how I was working with these models?

Undaunted by these disappointments, I thought I'd try my hand at something more adventureous, by going full "YOLO" mode and vibe-coding something entirely from scratch, using a language and framework I was far from expert in, just as all the vibe-coding CEO types are said to be doing. Towards this end, I decided on creating a native MacOS image browser application in Swift. While I've had an Apple Developer licence for more than a decade, and did put a little effort into learning Swift many years ago, I haven't had any real reason to write any Swift in all of that time, nor seen any need to create Mac-native applications. I would have to rely completely on these tools to autogenerate something that worked, without the option of jumping in and fixing any blocking issues that might arise.